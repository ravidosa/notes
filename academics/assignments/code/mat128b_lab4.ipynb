{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03fdedc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "0.022877769470214845 \t 1.866343893652811e-07 \t 3.1581661648546783e-09\n",
      "90.20300110816956 \t 3.5203752773327324e-07 \t 2.8822128973154576e-07\n",
      "0.05610614776611328 \t 2.682591991742811e-07 \t 6.642218563932942e-08\n",
      "2.6324415588378907 \t 4.338336559328582e-08 \t 8.773889635891821e+58\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#initialize matrices\n",
    "def matrix_init(n, test):\n",
    "    #dimensions of matrices n\n",
    "    if test == 1: #matrix from book\n",
    "        A = np.array([[-2, -3], [6, 7]], dtype=np.float32)\n",
    "    if test == 2: #A = 10I + B + B^T + B^TB\n",
    "        B = np.random.normal(size = (n, n))\n",
    "        Bt = np.transpose(B)\n",
    "        A = 10 * np.eye(n) + B + Bt + np.matmul(Bt, B)\n",
    "    return A\n",
    "\n",
    "#back substitution of upper triangular matrix\n",
    "def Backsolve(A, b, n): #based on algorithm 6.1\n",
    "    #coefficient of unknowns matrix A, constants matrix b\n",
    "    x = np.zeros((n,1))\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        x_i = b[i]\n",
    "        for j in range(i + 1, n):\n",
    "            x_i = x_i - A[i][j] * x[j]\n",
    "        x[i] = x_i/A[i][i]\n",
    "    return x\n",
    "\n",
    "#compute LU factorization of matrix\n",
    "def LU_factorize(A, n): #based on algorithm 6.4\n",
    "    #coefficient of unknowns matrix A\n",
    "    L = np.eye(n, dtype=np.float32) #set L_ii to 1 (identity matrix)\n",
    "    U = np.zeros((n, n), dtype=np.float32) #initialize U\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            u_ij = A[i][j] - np.dot(L[i,:], U[:,j])\n",
    "            l_ji = A[j][i] - np.dot(L[j,:], U[:,i])\n",
    "            U[i][j] = u_ij\n",
    "            L[j][i] = l_ji/U[i][i]\n",
    "    return L, U\n",
    "\n",
    "#front substitution of lower triangular matrix\n",
    "def LU_solve(L, U, b, n): #based on algorithm 6.1\n",
    "    #lower triangular matrix L, upper triangular matrix U, constants matrix b\n",
    "    y = np.zeros((n, 1))\n",
    "    for i in range(n): #front solve Ly = b for y\n",
    "        y_i = b[i]\n",
    "        for j in range(i):\n",
    "            y_i = y_i - L[i][j] * y[j]\n",
    "        y[i] = y_i/L[i][i]\n",
    "    return Backsolve(U, y, n) #back solve Ux = y for x\n",
    "\n",
    "epsilon = 1e-8 #tolerance, checked against absolute update\n",
    "\n",
    "#power method\n",
    "def power(A, x_0, n): #based on algorithm 9.1\n",
    "    #matrix A, initial guess x_0\n",
    "    x = x_0/np.linalg.norm(x_0, np.inf)\n",
    "    i = 0\n",
    "    lamda = 1\n",
    "    while True:\n",
    "        i += 1\n",
    "        x_t = x.copy()\n",
    "        x_t = np.dot(A, x_t)\n",
    "        lamda = np.linalg.norm(x_t, np.inf)\n",
    "        x_t = x_t/np.linalg.norm(x_t, np.inf)\n",
    "        if np.abs(np.linalg.norm(x - x_t)) <= epsilon:\n",
    "            x = x_t.copy()\n",
    "            break\n",
    "        x = x_t.copy()\n",
    "    return lamda, x\n",
    "\n",
    "#inverse power method\n",
    "def inverse_power(A, x_0, n): #based on algorithm 9.3\n",
    "    #matrix A, initial guess x_0\n",
    "    x = x_0/np.linalg.norm(x_0, np.inf)\n",
    "    L, U = LU_factorize(A, n)\n",
    "    i = 0\n",
    "    lamda = 1\n",
    "    while True:\n",
    "        i += 1\n",
    "        x_t = x.copy()\n",
    "        x_t = LU_solve(L, U, x_t, n) #solve using LU factorization\n",
    "        lamda = np.linalg.norm(x_t, np.inf)\n",
    "        x_t = x_t/np.linalg.norm(x_t, np.inf)\n",
    "        if np.abs(np.linalg.norm(x - x_t)) <= epsilon:\n",
    "            x = x_t.copy()\n",
    "            break\n",
    "        x = x_t.copy()\n",
    "    return 1/lamda, x\n",
    "\n",
    "def deflation_max(A, lamda, v, x_0, n): #based on algorithm 9.4\n",
    "    #matrix A, max eigenvalue lamda_max, eigenvector v_max, initial guess x_0\n",
    "    i = np.argmax(np.abs(v))\n",
    "    B = np.zeros((n - 1, n - 1))\n",
    "    for k in range(i):\n",
    "        for j in range(i):\n",
    "            B[k][j] = A[k][j] - v[k]/v[i]*A[i][j]\n",
    "    for k in range(i, n - 1):\n",
    "        for j in range(i):\n",
    "            B[k][j] = A[k + 1][j] - v[k + 1]/v[i]*A[i][j]\n",
    "            B[j][k] = A[j][k + 1] - v[j]/v[i]*A[i][k + 1]\n",
    "    for k in range(i, n - 1):\n",
    "        for j in range(i, n - 1):\n",
    "            B[k][j] = A[k + 1][j + 1] - v[k + 1]/v[i]*A[i][j + 1]\n",
    "    mu, w1 = power(B, x_0[:-1], n - 1)\n",
    "    w = np.insert(w1, i, 0)\n",
    "    u = np.zeros((n, 1))\n",
    "    for k in range(n):\n",
    "        u[k] = (mu - lamda) * w[k] + np.dot(A[i], w) * v[k]/v[i]\n",
    "    return mu, u\n",
    "def deflation_min(A, lamda, v, x_0, n): #based on algorithm 9.4\n",
    "    #matrix A, max eigenvalue lamda_max, eigenvector v_max, initial guess x_0\n",
    "    i = np.argmax(np.abs(v))\n",
    "    B = np.zeros((n - 1, n - 1))\n",
    "    for k in range(i):\n",
    "        for j in range(i):\n",
    "            B[k][j] = A[k][j] - v[k]/v[i]*A[i][j]\n",
    "    for k in range(i, n - 1):\n",
    "        for j in range(i):\n",
    "            B[k][j] = A[k + 1][j] - v[k + 1]/v[i]*A[i][j]\n",
    "            B[j][k] = A[j][k + 1] - v[j]/v[i]*A[i][k + 1]\n",
    "    for k in range(i, n - 1):\n",
    "        for j in range(i, n - 1):\n",
    "            B[k][j] = A[k + 1][j + 1] - v[k + 1]/v[i]*A[i][j + 1]\n",
    "    mu, w1 = power(B, x_0[:-1], n - 1)\n",
    "    w = np.insert(w1, i, 0)\n",
    "    u = np.zeros((n, 1))\n",
    "    for k in range(n):\n",
    "        u[k] = (mu - lamda) * w[k] + np.dot(A[i], w) * v[k]/v[i]\n",
    "    if n > 3:\n",
    "        mu, w1 = deflation_min(B, mu, w1, x_0[:-1], n - 1)\n",
    "        w = np.insert(w1, i, 0)\n",
    "        u = np.zeros((n, 1))\n",
    "        for k in range(n):\n",
    "            u[k] = (mu - lamda) * w[k] + np.dot(A[i], w) * v[k]/v[i]\n",
    "        return mu, u\n",
    "    else:\n",
    "        return mu, u\n",
    "        \n",
    "test = 2\n",
    "if test == 1:\n",
    "    n = 2\n",
    "    A = matrix_init(n, test)\n",
    "    x_0 = np.ones((n, 1))\n",
    "    \n",
    "    eigs, v = np.linalg.eig(A)\n",
    "    eigs = np.sort(eigs)\n",
    "    print(\"two lowest: \", eigs[0], eigs[1])\n",
    "    print(\"two highest: \", eigs[-1], eigs[-2])\n",
    "    \n",
    "    eig_max, v_max = power(A, x_0, n)\n",
    "    print(eig_max, v_max)\n",
    "    print(np.abs(eig_max - eigs[-1]), np.linalg.norm(np.dot(A, v_max) - np.dot(eig_max, v_max), np.inf)/np.abs(eigs[-1]))\n",
    "    eig_min, v_min = inverse_power(A, x_0, n)\n",
    "    print(eig_min, v_min)\n",
    "    print(np.abs(eig_min - eigs[0]), np.linalg.norm(np.dot(A, v_min) - np.dot(eig_min, v_min), np.inf)/np.abs(eigs[0]))\n",
    "if test == 2:\n",
    "    n = 50\n",
    "    time_max = np.array([]) #computation time for max eigenvalue\n",
    "    lamda_err_max = np.array([]) #eigenvalue error for max eigenvalue\n",
    "    vec_err_max = np.array([]) #eigenvector error for max eigenvalue\n",
    "    time_min = np.array([]) #computation time for min eigenvalue\n",
    "    lamda_err_min = np.array([]) #eigenvalue error for min eigenvalue\n",
    "    vec_err_min = np.array([]) #eigenvector error for min eigenvalue\n",
    "    time_max2 = np.array([]) #computation time for 2nd max eigenvalue\n",
    "    lamda_err_max2 = np.array([]) #eigenvalue error for 2nd max eigenvalue\n",
    "    vec_err_max2 = np.array([]) #eigenvector error for 2nd max eigenvalue\n",
    "    time_min2 = np.array([]) #computation time for min 2nd eigenvalue\n",
    "    lamda_err_min2 = np.array([]) #eigenvalue error for 2nd min eigenvalue\n",
    "    vec_err_min2 = np.array([]) #eigenvector error for 2nd min eigenvalue\n",
    "    \n",
    "    for i in range(25):\n",
    "        A = matrix_init(n, test)\n",
    "        x_0 = np.ones((n, 1))\n",
    "\n",
    "        eigs, v = np.linalg.eig(A)\n",
    "        eigs = np.sort(eigs)\n",
    "        #print(\"two lowest: \", eigs[0], eigs[1])\n",
    "        #print(\"two highest: \", eigs[-1], eigs[-2])\n",
    "        \n",
    "        t0_max = time.time()\n",
    "        eig_max, v_max = power(A, x_0, n)\n",
    "        t1_max = time.time()\n",
    "        time_max = np.append(time_max, t1_max - t0_max)\n",
    "        lamda_err_max = np.append(lamda_err_max, np.abs(eig_max - eigs[-1]))\n",
    "        vec_err_max = np.append(vec_err_max, np.linalg.norm(np.dot(A, v_max) - np.dot(eig_max, v_max), np.inf)/np.abs(eigs[-1]))\n",
    "        \n",
    "        t0_min = time.time()\n",
    "        eig_min, v_min = inverse_power(A, x_0, n)\n",
    "        t1_min = time.time()\n",
    "        time_min = np.append(time_min, t1_min - t0_min)\n",
    "        lamda_err_min = np.append(lamda_err_min, np.abs(eig_min - eigs[0]))\n",
    "        vec_err_min = np.append(vec_err_min, np.linalg.norm(np.dot(A, v_min) - np.dot(eig_min, v_min), np.inf)/np.abs(eigs[0]))\n",
    "        \n",
    "        t0_max2 = time.time()\n",
    "        eig_max2, v_max2 = deflation_max(A, eig_max, v_max, x_0, n)\n",
    "        t1_max2 = time.time()\n",
    "        time_max2 = np.append(time_max2, t1_max2 - t0_max2)\n",
    "        lamda_err_max2 = np.append(lamda_err_max2, np.abs(eig_max2 - eigs[-2]))\n",
    "        vec_err_max2 = np.append(vec_err_max2, np.linalg.norm(np.dot(A, v_max2) - np.dot(eig_max2, v_max2), np.inf)/np.abs(eigs[-2]))\n",
    "        \n",
    "        t0_min2 = time.time()\n",
    "        eig_min2, v_min2 = deflation_min(A, eig_max, v_max, x_0, n)\n",
    "        t1_min2 = time.time()\n",
    "        time_min2 = np.append(time_min2, t1_min2 - t0_min2)\n",
    "        lamda_err_min2 = np.append(lamda_err_min2, np.abs(eig_min2 - eigs[1]))\n",
    "        vec_err_min2 = np.append(vec_err_min2, np.linalg.norm(np.dot(A, v_min2) - np.dot(eig_min2, v_min2), np.inf)/np.abs(eigs[1]))\n",
    "        print(i) #progress tracker\n",
    "    \n",
    "    \n",
    "    print(np.average(time_max), \"\\t\", np.average(lamda_err_max), \"\\t\", np.average(vec_err_max))\n",
    "    print(np.average(time_min), \"\\t\", np.average(lamda_err_min), \"\\t\", np.average(vec_err_min))\n",
    "    print(np.average(time_max2), \"\\t\", np.average(lamda_err_max2), \"\\t\", np.average(vec_err_max2))\n",
    "    print(np.average(time_min2), \"\\t\", np.average(lamda_err_min2), \"\\t\", np.average(vec_err_min2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
